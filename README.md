# ğŸ¾ Wildlife MCP API ğŸ¾

The **Wildlife MCP API** powers geospatial and species identification tools using embeddings, AI, and ecoregion logic.  
It is designed for intelligent orchestration with AI agents and supports spatial queries, similarity search, and species lookups.  

---

## ğŸš¨ Notes

- **Supported species**: Currently limited to **North American mammals and birds**.  
- Additional ecoregions and species classes (e.g. reptiles, amphibians) are coming soon.  

---

## ğŸ” About MCP

This API is wrapped by **[FastAPI-MCP](https://github.com/modelcontextprotocol/fastapi-mcp)**, making endpoints **LLM-native tools**.  

- Endpoints are **discoverable via the OpenAPI spec**.  
- Compatible with **agentic workflows** (e.g., LangGraph, LangChain).  
- Enables **reasoning + orchestration** by AI systems.  

---

## ğŸ“¡ API Endpoints

| Endpoint | Description |
|----------|-------------|
| `/ecoregion/by-coordinates` | Lookup an ecoregion by latitude/longitude |
| `/species/by-ecoregion` | Get species present in a given ecoregion |
| `/species/identify-by-embedding` | Identify species using image embeddings |

---

## ğŸ›  Developer Resources

- ğŸ“˜ **Interactive Redoc** â€“ Explore and test API endpoints  
- ğŸ“œ **OpenAPI Spec** â€“ For programmatic discovery and agent integration  

---

## âš¡ Powered By

- ğŸŒ **WildFinder Database** â€” World Wildlife Fund (WWF)  
- ğŸ”Œ **FastAPI-MCP** â€” LLM-native tool wrapper for intelligent workflows  
- ğŸ **Python + FastAPI** â€” Core server logic and routing  
- ğŸ—º **PostgreSQL + PostGIS + PGVector** â€” Spatial + similarity search  
- ğŸ§  **OpenCLIP** â€” Multimodal embeddings for image + text similarity  
- ğŸ”— **LangGraph** â€” Agentic orchestration and decision-making  

---

## ğŸš€ Getting Started

1. Clone the repo:  
   ```bash
   git clone https://github.com/readcommitted/wildlife-vision-pipeline.git
   cd wildlife-vision-pipeline

## ğŸ“œ License

MIT License â€“ See [LICENSE](./LICENSE) for details.
